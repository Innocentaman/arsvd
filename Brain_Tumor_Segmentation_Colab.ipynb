{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {"id": "title"},
      "source": [
        "# Brain Tumor Segmentation with U-Net\n",
        "\n",
        "This notebook trains a U-Net model for brain tumor segmentation and compares **ARSVD vs SVD** compression methods.\n",
        "\n",
        "## Pipeline Options:\n",
        "- **Option A**: Run complete pipeline in ONE command (Training + Compression)\n",
        "- **Option B**: Step-by-step (Train first, then compression experiments separately)\n",
        "\n",
        "### Quick Start:\n",
        "1. Mount Google Drive and extract dataset\n",
        "2. Clone the repository\n",
        "3. Install dependencies\n",
        "4. Run Option A (complete pipeline) OR Option B (step-by-step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "step1"},
      "source": [
        "## Step 1: Mount Google Drive and Extract Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "mount-drive"},
      "outputs": [],
      "source": [
        "import os\n",
        "# Suppress TensorFlow warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "unzip-dataset"},
      "outputs": [],
      "source": [
        "# Extract the brain tumor dataset\n",
        "# Make sure to upload your dataset zip file to Google Drive first\n",
        "# Update the path below to point to your dataset zip file\n",
        "!unzip /content/drive/MyDrive/brain_tumor_dataset.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "step2"},
      "source": [
        "## Step 2: Clone the GitHub Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "clone-repo"},
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/Innocentaman/arsvd.git\n",
        "\n",
        "# Navigate to the project directory\n",
        "%cd arsvd\n",
        "\n",
        "# List the contents to verify\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "step3"},
      "source": [
        "## Step 3: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "install-deps"},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# TensorFlow 2.19.0 is already installed in Colab\n",
        "!pip install opencv-python numpy pandas scikit-learn tqdm scipy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "option-a"},
      "source": [
        "---\n",
        "\n",
        "## OPTION A: Complete Pipeline (One Command)\n",
        "\n",
        "**This runs EVERYTHING in a single command:**\n",
        "1. ‚úÖ Train U-Net model\n",
        "2. ‚úÖ Evaluate on test set\n",
        "3. ‚úÖ Run ARSVD compression experiments\n",
        "4. ‚úÖ Run SVD compression experiments\n",
        "5. ‚úÖ Generate comparison plots\n",
        "\n",
        "### Recommended for:\n",
        "- Full training runs (50+ epochs)\n",
        "- Complete experiments\n",
        "- Production use\n",
        "\n",
        "### Parameters:\n",
        "- `--epochs 1`: Change to `--epochs 50` for real training\n",
        "- `--run_compression`: Enables compression experiments\n",
        "- `--svd_ranks`: Test different fixed ranks\n",
        "- `--arsvd_taus`: Test different entropy thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "run-complete-pipeline"},
      "outputs": [],
      "source": [
        "# Run complete pipeline: Training + Compression Experiments\n",
        "# This will take time depending on epochs and number of experiments\n",
        "\n",
        "# For testing (1 epoch):\n",
        "!python run_complete_pipeline.py \\\n",
        "  --data_root /content/dataset/data \\\n",
        "  --epochs 1 \\\n",
        "  --batch_size 16 \\\n",
        "  --lr 1e-4 \\\n",
        "  --img_size 256 \\\n",
        "  --patience 20 \\\n",
        "  --lr_patience 5 \\\n",
        "  --svd_ranks \"50,100,150\" \\\n",
        "  --arsvd_taus \"0.95,0.9,0.85,0.8\" \\\n",
        "  --run_compression \\\n",
        "  --out_dir ./complete_results\n",
        "\n",
        "# For actual training (50+ epochs):\n",
        "# !python run_complete_pipeline.py \\\n",
        "#   --data_root /content/dataset/data \\\n",
        "#   --epochs 50 \\\n",
        "#   --batch_size 16 \\\n",
        "#   --lr 1e-4 \\\n",
        "#   --img_size 256 \\\n",
        "#   --patience 20 \\\n",
        "#   --lr_patience 5 \\\n",
        "#   --svd_ranks \"50,100,150\" \\\n",
        "#   --arsvd_taus \"0.95,0.9,0.85,0.8\" \\\n",
        "#   --run_compression \\\n",
        "#   --out_dir ./complete_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "option-b"},
      "source": [
        "---\n",
        "\n",
        "## OPTION B: Step-by-Step (Separate Commands)\n",
        "\n",
        "**Run training and compression separately**\n",
        "\n",
        "### Recommended for:\n",
        "- Testing and debugging\n",
        "- Understanding each step\n",
        "- Running compression on existing trained model\n",
        "\n",
        "### Steps:\n",
        "1. Train model first\n",
        "2. Then run compression experiments on trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "step-b1"},
      "source": [
        "### Step B1: Train U-Net Model Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "train-only"},
      "outputs": [],
      "source": [
        "# Train and evaluate U-Net model\n",
        "# Change --epochs 1 to --epochs 50 for actual training\n",
        "\n",
        "!python run_pipeline.py \\\n",
        "  --data_root /content/dataset/data \\\n",
        "  --out_dir ./artifacts \\\n",
        "  --epochs 1 \\\n",
        "  --batch_size 16 \\\n",
        "  --lr 1e-4 \\\n",
        "  --img_size 256 \\\n",
        "  --patience 20 \\\n",
        "  --lr_patience 5 \\\n",
        "  --seed 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "step-b2"},
      "source": [
        "### Step B2: Run Compression Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "compression-only"},
      "outputs": [],
      "source": [
        "# Run ARSVD vs SVD compression experiments on trained model\n",
        "# Uses the model trained in previous step\n",
        "\n",
        "!python run_compression_pipeline.py \\\n",
        "  --data_root /content/dataset/data \\\n",
        "  --model_path ./artifacts/model.h5 \\\n",
        "  --svd_ranks \"50,100,150\" \\\n",
        "  --arsvd_taus \"0.95,0.9,0.85,0.8\" \\\n",
        "  --batch_size 16 \\\n",
        "  --img_size 256 \\\n",
        "  --out_dir ./compression_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "view-results"},
      "source": [
        "---\n",
        "\n",
        "## View Results\n",
        "\n",
        "The following cells work for **both Option A and Option B**.\n",
        "\n",
        "Results locations:\n",
        "- Option A: `./complete_results/`\n",
        "- Option B: `./artifacts/` (training) and `./compression_results/` (compression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "training-results"},
      "source": [
        "### Training Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "view-training-metrics"},
      "outputs": [],
      "source": [
        "# Display training metrics\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Detect which option was run\n",
        "if os.path.exists('./complete_results/training/log.csv'):\n",
        "    log_path = './complete_results/training/log.csv'\n",
        "    score_path = './complete_results/training/score.csv'\n",
        "    results_dir = './complete_results/training/results'\n",
        "    print('Using Option A results (complete pipeline)')\n",
        "elif os.path.exists('./artifacts/log.csv'):\n",
        "    log_path = './artifacts/log.csv'\n",
        "    score_path = './artifacts/score.csv'\n",
        "    results_dir = './artifacts/results'\n",
        "    print('Using Option B results (step-by-step)')\n",
        "else:\n",
        "    print('No training results found! Please run training first.')\n",
        "\n",
        "# Load and display training history\n",
        "if 'log_path' in locals():\n",
        "    log_df = pd.read_csv(log_path)\n",
        "    print(\"Training History:\")\n",
        "    print(log_df.tail())\n",
        "    \n",
        "    # Plot training curves\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(log_df['epoch'], log_df['loss'], label='Train Loss')\n",
        "    plt.plot(log_df['epoch'], log_df['val_loss'], label='Val Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(log_df['epoch'], log_df['dice_coef'], label='Train Dice Coef')\n",
        "    plt.plot(log_df['epoch'], log_df['val_dice_coef'], label='Val Dice Coef')\n",
        "    plt.title('Training and Validation Dice Coefficient')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Dice Coefficient')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "view-test-metrics"},
      "outputs": [],
      "source": [
        "# Display test metrics\n",
        "if 'score_path' in locals():\n",
        "    score_df = pd.read_csv(score_path)\n",
        "    print(\"\\nTest Results:\")\n",
        "    print(f\"Average F1 Score: {score_df['F1'].mean():.4f}\")\n",
        "    print(f\"Average Jaccard Index: {score_df['Jaccard'].mean():.4f}\")\n",
        "    print(f\"Average Recall: {score_df['Recall'].mean():.4f}\")\n",
        "    print(f\"Average Precision: {score_df['Precision'].mean():.4f}\")\n",
        "    \n",
        "    print(\"\\nPer-image results:\")\n",
        "    print(score_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "display-predictions"},
      "outputs": [],
      "source": [
        "# Display some prediction results\n",
        "from IPython.display import Image, display\n",
        "\n",
        "if 'results_dir' in locals() and os.path.exists(results_dir):\n",
        "    result_images = sorted(os.listdir(results_dir))[:5]  # Display first 5 results\n",
        "    \n",
        "    for img_name in result_images:\n",
        "        img_path = os.path.join(results_dir, img_name)\n",
        "        print(f\"\\n{img_name}\")\n",
        "        display(Image(filename=img_path, width=800))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "compression-results-section"},
      "source": [
        "### Compression Results (ARSVD vs SVD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "view-compression-summary"},
      "outputs": [],
      "source": [
        "# Load and display compression results\n",
        "import pandas as pd\n",
        "\n",
        "# Detect which option was run\n",
        "if os.path.exists('./complete_results/compression/compression_summary.csv'):\n",
        "    compression_csv = './complete_results/compression/compression_summary.csv'\n",
        "    compression_plots = './complete_results/compression/plots'\n",
        "    print('Using Option A compression results')\n",
        "elif os.path.exists('./compression_results/compression_summary.csv'):\n",
        "    compression_csv = './compression_results/compression_summary.csv'\n",
        "    compression_plots = './compression_results/plots'\n",
        "    print('Using Option B compression results')\n",
        "else:\n",
        "    print('No compression results found! Please run compression experiments first.')\n",
        "\n",
        "# Display summary table\n",
        "if 'compression_csv' in locals():\n",
        "    summary_df = pd.read_csv(compression_csv)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPRESSION EXPERIMENTS SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(summary_df.to_string(index=False))\n",
        "    print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "display-compression-plots"},
      "outputs": [],
      "source": [
        "# Display all comparison plots\n",
        "from IPython.display import Image, display\n",
        "\n",
        "if 'compression_plots' in locals() and os.path.exists(compression_plots):\n",
        "    plot_files = sorted([f for f in os.listdir(compression_plots) if f.endswith('.png')])\n",
        "    \n",
        "    for plot_file in plot_files:\n",
        "        plot_path = os.path.join(compression_plots, plot_file)\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"{plot_file.replace('_', ' ').title().replace('.png', '')}\")\n",
        "        print(f\"{'='*80}\")\n",
        "        display(Image(filename=plot_path, width=1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "analysis-section"},
      "source": [
        "### Analysis and Key Findings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "analyze-results"},
      "outputs": [],
      "source": [
        "# Compare baseline vs compressed models\n",
        "if 'compression_csv' in locals():\n",
        "    summary_df = pd.read_csv(compression_csv)\n",
        "    \n",
        "    baseline = summary_df[summary_df['method'] == 'none'].iloc[0]\n",
        "    svd_results = summary_df[summary_df['method'] == 'svd']\n",
        "    arsvd_results = summary_df[summary_df['method'] == 'arsvd']\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"KEY FINDINGS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    print(f\"\\nüìä BASELINE MODEL (No Compression):\")\n",
        "    print(f\"   Dice: {baseline['dice']:.4f}\")\n",
        "    print(f\"   IoU: {baseline['iou']:.4f}\")\n",
        "    print(f\"   F1: {baseline['f1']:.4f}\")\n",
        "    \n",
        "    print(f\"\\nüîß SVD COMPRESSION (Fixed Rank):\")\n",
        "    for _, row in svd_results.iterrows():\n",
        "        dice_drop = baseline['dice'] - row['dice']\n",
        "        print(f\"   Rank {int(row['param_value'])}: Dice={row['dice']:.4f} (drop: {dice_drop:.4f})\")\n",
        "    \n",
        "    print(f\"\\nüéØ ARSVD COMPRESSION (Adaptive Rank):\")\n",
        "    for _, row in arsvd_results.iterrows():\n",
        "        dice_drop = baseline['dice'] - row['dice']\n",
        "        print(f\"   Tau {row['param_value']:.2f}: Dice={row['dice']:.4f} (drop: {dice_drop:.4f})\")\n",
        "    \n",
        "    # Find best configurations\n",
        "    if len(svd_results) > 0:\n",
        "        best_svd = svd_results.loc[svd_results['dice'].idxmax()]\n",
        "        print(f\"\\nüèÜ BEST COMPRESSED MODELS:\")\n",
        "        print(f\"   SVD: Rank {int(best_svd['param_value'])} with Dice={best_svd['dice']:.4f}\")\n",
        "    \n",
        "    if len(arsvd_results) > 0:\n",
        "        best_arsvd = arsvd_results.loc[arsvd_results['dice'].idxmax()]\n",
        "        print(f\"   ARSVD: Tau={best_arsvd['param_value']:.2f} with Dice={best_arsvd['dice']:.4f}\")\n",
        "    \n",
        "    if len(svd_results) > 0 and len(arsvd_results) > 0:\n",
        "        arsvd_better = best_arsvd['dice'] > best_svd['dice']\n",
        "        if arsvd_better:\n",
        "            print(f\"\\n‚úÖ ARSVD outperforms SVD by {best_arsvd['dice'] - best_svd['dice']:.4f} Dice points\")\n",
        "        else:\n",
        "            print(f\"\\n‚ö†Ô∏è  SVD outperforms ARSVD by {best_svd['dice'] - best_arsvd['dice']:.4f} Dice points\")\n",
        "    \n",
        "    print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "save-results"},
      "source": [
        "## Save Results to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "save-to-drive"},
      "outputs": [],
      "source": [
        "# Copy all results to Google Drive for permanent storage\n",
        "\n",
        "if os.path.exists('./complete_results'):\n",
        "    !cp -r ./complete_results /content/drive/MyDrive/brain_tumor_complete_results\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚úÖ OPTION A RESULTS SAVED\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"Location: /content/drive/MyDrive/brain_tumor_complete_results\")\n",
        "    print(\"\\nContents:\")\n",
        "    print(\"  - training/model.h5 (trained model)\")\n",
        "    print(\"  - training/score.csv (test metrics)\")\n",
        "    print(\"  - training/results/ (sample predictions)\")\n",
        "    print(\"  - compression/compression_summary.csv (all experiments)\")\n",
        "    print(\"  - compression/plots/ (comparison visualizations)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "elif os.path.exists('./artifacts'):\n",
        "    !cp -r ./artifacts /content/drive/MyDrive/brain_tumor_segmentation_results\n",
        "    print(\"\\n‚úÖ Training results saved to: /content/drive/MyDrive/brain_tumor_segmentation_results\")\n",
        "\n",
        "if os.path.exists('./compression_results'):\n",
        "    !cp -r ./compression_results /content/drive/MyDrive/brain_tumor_compression_results\n",
        "    print(\"‚úÖ Compression results saved to: /content/drive/MyDrive/brain_tumor_compression_results\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
